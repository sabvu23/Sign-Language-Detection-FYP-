# -*- coding: utf-8 -*-
"""Data_Pre-processing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eoxrb_eaT_uD0SEaAcjY87ZGfxWlEPaD
"""

from google.colab import drive
import zipfile
import os
from PIL import Image
import numpy as np
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

drive.mount('/content/drive')

# Define the path to your zip file
zip_file_path = '/content/drive/MyDrive/Colab Notebooks/Dataset.zip'

# Define the folder where you want to extract the contents
extract_folder = '/content/Colab Notebooks/Dataset.zip'

# Unzip the file
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extract_folder)

print(f"Files extracted to {extract_folder}")

extracted_files = os.listdir(extract_folder)
print(extracted_files)

# Update with your folder path

# List all files in the folder
files = os.listdir(extract_folder)

# Display the number of files and some sample file names
print(f"Total files: {len(files)}")
print(f"Sample files: {files[:10]}")  # Display first 10 files for a quick check

# Define the path to the 'asl_alphabet_train' folder
alphabet_train_folder = os.path.join(extract_folder, 'Dataset', 'asl_alphabet_train', 'asl_alphabet_train')

# List all alphabet folders within 'asl_alphabet_train'
alphabet_folders = [f for f in os.listdir(alphabet_train_folder) if os.path.isdir(os.path.join(alphabet_train_folder, f))]

# Initialize a variable to track image shapes
all_images_same_shape = True

# Iterate through alphabet folders and image files
for alphabet_folder in alphabet_folders:
    for image_file in os.listdir(os.path.join(alphabet_train_folder, alphabet_folder)):
        image_path = os.path.join(alphabet_train_folder, alphabet_folder, image_file)

        try:
            image = Image.open(image_path)
            image_array = np.array(image)

            if image_array.shape != (200, 200, 3):
                all_images_same_shape = False
                print(f"Image with different shape found: {image_path}, Shape: {image_array.shape}")
                break  # Exit the inner loop if a different shape is found

        except Exception as e:
            print(f"Error processing image: {image_path}, Error: {e}")
            all_images_same_shape = False
            break  # Exit the inner loop if there's an error

    if not all_images_same_shape:
        break  # Exit the outer loop if a different shape is found

if all_images_same_shape:
    print("All images in the training dataset have the shape (200, 200, 3)")
else:
    print("Not all images in the training dataset have the same shape.")

def load_and_normalize_image(image_path):
    image = load_img(image_path, target_size=(64, 64))  # Assuming the images are 64x64
    image_array = img_to_array(image) / 255.0  # Normalize the pixel values to the range [0, 1]
    return image_array

# Assuming 'extract_folder' and 'alphabet_train_folder' are defined as in your previous code:

# Define the path to the 'asl_alphabet_train' folder
alphabet_train_folder = os.path.join(extract_folder, 'Dataset', 'asl_alphabet_train', 'asl_alphabet_train')

# Create a list to store all image paths
image_paths = []
labels = []

# List all alphabet folders within 'asl_alphabet_train'
alphabet_folders = [f for f in os.listdir(alphabet_train_folder) if os.path.isdir(os.path.join(alphabet_train_folder, f))]

# Iterate through alphabet folders and image files to collect image paths
for alphabet_folder in alphabet_folders:
    for image_file in os.listdir(os.path.join(alphabet_train_folder, alphabet_folder)):
        image_path = os.path.join(alphabet_train_folder, alphabet_folder, image_file)
        image_paths.append(image_path)  # Add the image path to the list
        labels.append(alphabet_folder)

# Load and normalize all images
image_data = [load_and_normalize_image(path) for path in image_paths]

# Convert the list to a NumPy array
image_data = np.array(image_data)
labels = np.array(labels)
label_encoder = LabelEncoder()
numeric_labels = label_encoder.fit_transform(labels)

# Display the shape of the data
print(f"Image data shape: {image_data.shape}")

# Split the data into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(image_data, numeric_labels, test_size=0.2, random_state=42)

# Further split the training data into training and validation sets (80% train, 20% validation)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

# Display the shape of the splits
print(f"Training data shape: {X_train.shape}")
print(f"Validation data shape: {X_val.shape}")
print(f"Test data shape: {X_test.shape}")

