# -*- coding: utf-8 -*-
"""FYP_Pre_Processing_Vowels.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OGzeeqKRc7L7R8chOu3Y67dspnLvRXmt
"""

from google.colab import drive
import zipfile
import os
from PIL import Image
import numpy as np
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.utils import to_categorical
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.models import load_model
import cv2
from google.colab import files

drive.mount('/content/drive')

# Define the path to your zip file
zip_file_path = '/content/drive/MyDrive/Colab Notebooks/Dataset_Vowels.zip'

# Define the folder where you want to extract the contents
extract_folder = '/content/Colab Notebooks/Dataset_Vowels.zip'

# Unzip the file
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extract_folder)

print(f"Files extracted to {extract_folder}")

extracted_files = os.listdir(extract_folder)
print(extracted_files)

# Define the dataset folder
dataset_folder = extract_folder

# Check for folders corresponding to alphabets
alphabet_folders = [f for f in os.listdir(dataset_folder) if os.path.isdir(os.path.join(dataset_folder, f))]

if not alphabet_folders:
    print("No alphabet folders found in the dataset. Please check the dataset structure.")
else:
    print(f"Alphabet folders found: {alphabet_folders[:5]}")  # Display first 5 folders for verification

# Initialize a variable to track image shapes
all_images_same_shape = True

# Iterate through alphabet folders and image files
for alphabet_folder in alphabet_folders:
    alphabet_folder_path = os.path.join(dataset_folder, alphabet_folder)

    for image_file in os.listdir(alphabet_folder_path):
        image_path = os.path.join(alphabet_folder_path, image_file)

        # Skip if the current item is a directory
        if os.path.isdir(image_path):
            continue

        try:
            # Open the image and convert it to a NumPy array
            image = Image.open(image_path)
            image_array = np.array(image)

            # Check if the image has the desired shape (200, 200, 3)
            if image_array.shape != (200, 200, 3):
                all_images_same_shape = False
                print(f"Image with different shape found: {image_path}, Shape: {image_array.shape}")
                break  # Exit the inner loop if a different shape is found

        except Exception as e:
            print(f"Error processing image: {image_path}, Error: {e}")
            all_images_same_shape = False
            break  # Exit the inner loop if there's an error

    if not all_images_same_shape:
        break  # Exit the outer loop if a different shape is found

# Final result
if all_images_same_shape:
    print("All images in the dataset have the shape (200, 200, 3).")
else:
    print("Not all images in the dataset have the same shape.")

def load_and_normalize_image(image_path):
    image = load_img(image_path, target_size=(64, 64))  # Assuming the images are 64x64
    image_array = img_to_array(image) / 255.0  # Normalize the pixel values to the range [0, 1]
    return image_array

# Assuming 'extract_folder' and 'alphabet_train_folder' are defined as in your previous code:

# Define the path to the 'asl_alphabet_train' folder
alphabet_train_folder = os.path.join(extract_folder, 'Dataset_Vowels')

# Create a list to store all image paths
image_paths = []
labels = []

# List all alphabet folders within 'asl_alphabet_train'
alphabet_folders = [f for f in os.listdir(alphabet_train_folder) if os.path.isdir(os.path.join(alphabet_train_folder, f))]

# Iterate through alphabet folders and image files to collect image paths
for alphabet_folder in alphabet_folders:
    for image_file in os.listdir(os.path.join(alphabet_train_folder, alphabet_folder)):
        image_path = os.path.join(alphabet_train_folder, alphabet_folder, image_file)
        image_paths.append(image_path)  # Add the image path to the list
        labels.append(alphabet_folder)
# Load and normalize all images
image_data = [load_and_normalize_image(path) for path in image_paths]

# Convert the list to a NumPy array
image_data = np.array(image_data)
labels = np.array(labels)
label_encoder = LabelEncoder()
numeric_labels = label_encoder.fit_transform(labels)

# Display the shape of the data
print(f"Image data shape: {image_data.shape}")

# Split the data into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(image_data, numeric_labels, test_size=0.2, random_state=42)

# Further split the training data into training and validation sets (80% train, 20% validation)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

# Display the shape of the splits
print(f"Training data shape: {X_train.shape}")
print(f"Validation data shape: {X_val.shape}")
print(f"Test data shape: {X_test.shape}")

# Convert numeric labels to one-hot encoded labels
num_classes = len(label_encoder.classes_)  # Number of unique classes
y_train = to_categorical(y_train, num_classes)
y_val = to_categorical(y_val, num_classes)
y_test = to_categorical(y_test, num_classes)

print(f"One-hot encoded training labels shape: {y_train.shape}")

model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=X_train.shape[1:]),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(num_classes, activation='softmax')  # Output layer with 'num_classes' units
])

model.summary()

model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=10,  # You can increase epochs for better accuracy
    batch_size=32
)

test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {test_accuracy:.2f}")

model.save('sign_language_model.h5')
print("Model saved as 'sign_language_model.h5'")

# Load the trained model
model = load_model('sign_language_model.h5')
print("Model loaded successfully.")

def preprocess_image(image, target_size):
    # Resize the image
    image_resized = cv2.resize(image, target_size)
    # Normalize pixel values to [0, 1]
    image_normalized = image_resized / 255.0
    # Add batch dimension (1, height, width, channels)
    return np.expand_dims(image_normalized, axis=0)

# Function to preprocess the image
def preprocess_image(image, target_size):
    image = cv2.resize(image, target_size)  # Resize to target size
    image = image / 255.0  # Normalize pixel values
    image = np.expand_dims(image, axis=0)  # Add batch dimension
    return image

# Let user upload an image
uploaded = files.upload()  # Allows the user to upload a file

# Get the first uploaded file
for file_name in uploaded.keys():
    test_image_path = file_name
    break

# Load the uploaded image
test_image = cv2.imread(test_image_path)

# Ensure image is loaded properly
if test_image is not None:
    target_size = (64, 64)  # Replace with your model's input size
    processed_image = preprocess_image(test_image, target_size)

    # Make a prediction
    predictions = model.predict(processed_image)
    predicted_class = np.argmax(predictions, axis=1)[0]

    # Decode the class label
    class_label = label_encoder.inverse_transform([predicted_class])[0]
    print(f"Predicted Class: {class_label}")
else:
    print("Error: Could not load the image. Please check the file and try again.")

